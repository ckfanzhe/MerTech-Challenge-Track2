{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "import gc\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train=pd.read_pickle(\"../processed_data/df_train2.pkl\")\n",
    "feature_test=pd.read_pickle(\"../processed_data/df_test2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['android_id', 'apptype', 'carrier', 'dev_height', 'dev_ppi',\n       'dev_width', 'label', 'lan', 'media_id', 'ntt', 'os', 'osv', 'package',\n       'timestamp', 'version', 'fea_hash', 'location', 'fea1_hash', 'cus_type',\n       'truetime', 'day', 'hour', 'minute', 'mynull1', 'mynull2',\n       'dev_ppi_pred', 'final_ppi', '160_height', '160_width', '160_ppi',\n       'hw_ratio', 'hw_matrix', 'inch', 'vpn'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "feature_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['android_id', 'apptype', 'carrier', 'dev_height', 'dev_ppi',\n       'dev_width', 'lan', 'media_id', 'ntt', 'os', 'osv', 'package',\n       'timestamp', 'version', 'fea_hash', 'location', 'fea1_hash', 'cus_type',\n       'label', 'truetime', 'day', 'hour', 'minute', 'mynull1', 'mynull2',\n       'dev_ppi_pred', 'final_ppi', '160_height', '160_width', '160_ppi',\n       'hw_ratio', 'hw_matrix', 'inch', 'vpn'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "feature_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 归一化normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['hw_ratio', 'inch','final_ppi', 'hw_matrix']:\n",
    "    feature_train[col]=(feature_train[col] - feature_train[col].mean()) / (feature_train[col].std())\n",
    "    feature_test[col]=(feature_test[col] - feature_test[col].mean()) / (feature_test[col].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_feature = ['apptype', 'carrier', 'lan', 'media_id', 'ntt', 'os', 'osv', 'package', 'version', 'location', 'fea1_hash',\"fea_hash\", 'cus_type', '160_height', '160_width','160_ppi','vpn']\n",
    "for item in cate_feature:\n",
    "    le=preprocessing.LabelEncoder()\n",
    "    feature_train[item] = le.fit_transform(feature_train[item])\n",
    "    feature_test[item] = le.transform(feature_test[item])\n",
    "\n",
    "prediction = feature_test[['apptype', 'carrier', 'dev_height','hour', 'minute',\"timestamp\",\"day\",\n",
    "       'dev_width', 'lan', 'media_id', 'ntt', 'os', 'osv', 'package', 'version', 'fea_hash', 'location', 'fea1_hash', 'cus_type', '160_height', '160_width','160_ppi', 'hw_ratio', 'inch','final_ppi','vpn', 'hw_matrix']]\n",
    "prediction_train = feature_train[['apptype', 'carrier', 'dev_height','hour', 'minute',\"timestamp\",\"day\",\n",
    "       'dev_width', 'lan', 'media_id', 'ntt', 'os', 'osv', 'package', 'version', 'fea_hash', 'location', 'fea1_hash', 'cus_type', '160_height', '160_width','160_ppi', 'hw_ratio', 'inch','final_ppi','vpn', 'hw_matrix']]\n",
    "\n",
    "prediction['label'] = 0\n",
    "prediction_train['label'] = 0\n",
    "prediction_train['label_prior'] =  feature_train.label.values\n",
    "\n",
    "\n",
    "y_col = 'label'\n",
    "x_col=['apptype', 'carrier', 'dev_height','hour', 'minute',\"timestamp\",\"day\",\n",
    "       'dev_width', 'lan', 'media_id', 'ntt', 'os', 'osv', 'package', 'version', 'fea_hash', 'location', 'fea1_hash', 'cus_type', '160_height', '160_width','160_ppi', 'hw_ratio', 'inch','final_ppi','vpn', 'hw_matrix']\n",
    "# x_col = ['apptype', 'carrier', 'dev_height', 'dev_ppi','timestamp',\n",
    "#        'dev_width', 'lan', 'media_id', 'ntt', 'os', 'osv', 'package', 'version', 'fea_hash', 'location', 'fea1_hash', 'cus_type',\n",
    "#        'Day', 'Hour', 'apptype_most_index', 'apptype_most_freq', 'carrier_most_index', 'carrier_most_freq',\n",
    "#        'lan_most_index', 'lan_most_freq', 'media_id_most_index',\n",
    "#        'media_id_most_freq', 'ntt_most_index', 'ntt_most_freq',\n",
    "#        'os_most_index', 'os_most_freq', 'osv_most_index', 'osv_most_freq',\n",
    "#        'package_most_index', 'package_most_freq', 'version_most_index',\n",
    "#        'version_most_freq', 'location_most_index', 'location_most_freq',\n",
    "#        'fea1_hash_most_index', 'fea1_hash_most_freq', 'cus_type_most_index',\n",
    "#        'cus_type_most_freq', 'Day_most_index', 'Day_most_freq',\n",
    "#        'Hour_most_index', 'Hour_most_freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nFold_1 Training ================================\n\nTraining until validation scores don't improve for 400 rounds\n[100]\ttrain's binary_error: 0.113358\tvalid's binary_error: 0.11566\n[200]\ttrain's binary_error: 0.10992\tvalid's binary_error: 0.11328\n[300]\ttrain's binary_error: 0.108104\tvalid's binary_error: 0.112\n[400]\ttrain's binary_error: 0.106449\tvalid's binary_error: 0.11136\n[500]\ttrain's binary_error: 0.105233\tvalid's binary_error: 0.1113\n[600]\ttrain's binary_error: 0.103804\tvalid's binary_error: 0.11052\n[700]\ttrain's binary_error: 0.102571\tvalid's binary_error: 0.1103\n[800]\ttrain's binary_error: 0.101509\tvalid's binary_error: 0.10998\n[900]\ttrain's binary_error: 0.100533\tvalid's binary_error: 0.1096\n[1000]\ttrain's binary_error: 0.0996489\tvalid's binary_error: 0.10984\n[1100]\ttrain's binary_error: 0.0987733\tvalid's binary_error: 0.10962\n[1200]\ttrain's binary_error: 0.09786\tvalid's binary_error: 0.1096\n[1300]\ttrain's binary_error: 0.0969822\tvalid's binary_error: 0.10962\n[1400]\ttrain's binary_error: 0.0959\tvalid's binary_error: 0.10962\n[1500]\ttrain's binary_error: 0.0949489\tvalid's binary_error: 0.1094\n[1600]\ttrain's binary_error: 0.0939756\tvalid's binary_error: 0.1095\n[1700]\ttrain's binary_error: 0.0931089\tvalid's binary_error: 0.10954\n[1800]\ttrain's binary_error: 0.09228\tvalid's binary_error: 0.10964\nEarly stopping, best iteration is:\n[1466]\ttrain's binary_error: 0.0951733\tvalid's binary_error: 0.10924\n\nFold_2 Training ================================\n\nTraining until validation scores don't improve for 400 rounds\n[100]\ttrain's binary_error: 0.113693\tvalid's binary_error: 0.11328\n[200]\ttrain's binary_error: 0.110049\tvalid's binary_error: 0.11044\n[300]\ttrain's binary_error: 0.108116\tvalid's binary_error: 0.1103\n[400]\ttrain's binary_error: 0.106493\tvalid's binary_error: 0.10998\n[500]\ttrain's binary_error: 0.105353\tvalid's binary_error: 0.10936\n[600]\ttrain's binary_error: 0.104167\tvalid's binary_error: 0.10892\n[700]\ttrain's binary_error: 0.103051\tvalid's binary_error: 0.10872\n[800]\ttrain's binary_error: 0.102036\tvalid's binary_error: 0.10846\n[900]\ttrain's binary_error: 0.100833\tvalid's binary_error: 0.10826\n[1000]\ttrain's binary_error: 0.0999333\tvalid's binary_error: 0.10822\n[1100]\ttrain's binary_error: 0.0989467\tvalid's binary_error: 0.10812\n[1200]\ttrain's binary_error: 0.0979378\tvalid's binary_error: 0.10782\n[1300]\ttrain's binary_error: 0.0970378\tvalid's binary_error: 0.10804\n[1400]\ttrain's binary_error: 0.09592\tvalid's binary_error: 0.10782\n[1500]\ttrain's binary_error: 0.0949933\tvalid's binary_error: 0.1078\n[1600]\ttrain's binary_error: 0.0940578\tvalid's binary_error: 0.10786\nEarly stopping, best iteration is:\n[1216]\ttrain's binary_error: 0.0977511\tvalid's binary_error: 0.10766\n\nFold_3 Training ================================\n\nTraining until validation scores don't improve for 400 rounds\n[100]\ttrain's binary_error: 0.113176\tvalid's binary_error: 0.115\n[200]\ttrain's binary_error: 0.109838\tvalid's binary_error: 0.1126\n[300]\ttrain's binary_error: 0.108182\tvalid's binary_error: 0.11186\n[400]\ttrain's binary_error: 0.106604\tvalid's binary_error: 0.11144\n[500]\ttrain's binary_error: 0.105553\tvalid's binary_error: 0.11112\n[600]\ttrain's binary_error: 0.104093\tvalid's binary_error: 0.11092\n[700]\ttrain's binary_error: 0.102833\tvalid's binary_error: 0.11066\n[800]\ttrain's binary_error: 0.101971\tvalid's binary_error: 0.11024\n[900]\ttrain's binary_error: 0.100991\tvalid's binary_error: 0.11016\n[1000]\ttrain's binary_error: 0.100002\tvalid's binary_error: 0.1098\n[1100]\ttrain's binary_error: 0.0990356\tvalid's binary_error: 0.10958\n[1200]\ttrain's binary_error: 0.0979244\tvalid's binary_error: 0.1097\n[1300]\ttrain's binary_error: 0.0969067\tvalid's binary_error: 0.1096\n[1400]\ttrain's binary_error: 0.0959444\tvalid's binary_error: 0.10956\n[1500]\ttrain's binary_error: 0.0949044\tvalid's binary_error: 0.1095\n[1600]\ttrain's binary_error: 0.0939178\tvalid's binary_error: 0.10936\n[1700]\ttrain's binary_error: 0.0930644\tvalid's binary_error: 0.1096\n[1800]\ttrain's binary_error: 0.0922222\tvalid's binary_error: 0.1094\n[1900]\ttrain's binary_error: 0.0913311\tvalid's binary_error: 0.10942\n[2000]\ttrain's binary_error: 0.0902644\tvalid's binary_error: 0.10954\nEarly stopping, best iteration is:\n[1606]\ttrain's binary_error: 0.0939067\tvalid's binary_error: 0.10924\n\nFold_4 Training ================================\n\nTraining until validation scores don't improve for 400 rounds\n[100]\ttrain's binary_error: 0.11328\tvalid's binary_error: 0.11348\n[200]\ttrain's binary_error: 0.1098\tvalid's binary_error: 0.11224\n[300]\ttrain's binary_error: 0.107989\tvalid's binary_error: 0.11174\n[400]\ttrain's binary_error: 0.10664\tvalid's binary_error: 0.11128\n[500]\ttrain's binary_error: 0.105344\tvalid's binary_error: 0.11074\n[600]\ttrain's binary_error: 0.104084\tvalid's binary_error: 0.10994\n[700]\ttrain's binary_error: 0.102996\tvalid's binary_error: 0.10982\n[800]\ttrain's binary_error: 0.10198\tvalid's binary_error: 0.10956\n[900]\ttrain's binary_error: 0.100987\tvalid's binary_error: 0.10936\n[1000]\ttrain's binary_error: 0.09994\tvalid's binary_error: 0.10896\n[1100]\ttrain's binary_error: 0.0989489\tvalid's binary_error: 0.10896\n[1200]\ttrain's binary_error: 0.09802\tvalid's binary_error: 0.10852\n[1300]\ttrain's binary_error: 0.0968933\tvalid's binary_error: 0.10828\n[1400]\ttrain's binary_error: 0.0959756\tvalid's binary_error: 0.1084\n[1500]\ttrain's binary_error: 0.0950244\tvalid's binary_error: 0.10838\n[1600]\ttrain's binary_error: 0.0940267\tvalid's binary_error: 0.10838\n[1700]\ttrain's binary_error: 0.09318\tvalid's binary_error: 0.10846\n[1800]\ttrain's binary_error: 0.0923689\tvalid's binary_error: 0.10824\n[1900]\ttrain's binary_error: 0.0913133\tvalid's binary_error: 0.10824\n[2000]\ttrain's binary_error: 0.0902933\tvalid's binary_error: 0.10848\n[2100]\ttrain's binary_error: 0.08956\tvalid's binary_error: 0.10836\n[2200]\ttrain's binary_error: 0.0887578\tvalid's binary_error: 0.10842\nEarly stopping, best iteration is:\n[1879]\ttrain's binary_error: 0.0915644\tvalid's binary_error: 0.10806\n\nFold_5 Training ================================\n\nTraining until validation scores don't improve for 400 rounds\n[100]\ttrain's binary_error: 0.112907\tvalid's binary_error: 0.11378\n[200]\ttrain's binary_error: 0.109987\tvalid's binary_error: 0.11174\n[300]\ttrain's binary_error: 0.10834\tvalid's binary_error: 0.11034\n[400]\ttrain's binary_error: 0.106836\tvalid's binary_error: 0.11006\n[500]\ttrain's binary_error: 0.105596\tvalid's binary_error: 0.1096\n[600]\ttrain's binary_error: 0.104431\tvalid's binary_error: 0.10914\n[700]\ttrain's binary_error: 0.103104\tvalid's binary_error: 0.1087\n[800]\ttrain's binary_error: 0.102182\tvalid's binary_error: 0.10844\n[900]\ttrain's binary_error: 0.101002\tvalid's binary_error: 0.10788\n[1000]\ttrain's binary_error: 0.0998956\tvalid's binary_error: 0.1076\n[1100]\ttrain's binary_error: 0.0989978\tvalid's binary_error: 0.10732\n[1200]\ttrain's binary_error: 0.0979422\tvalid's binary_error: 0.10716\n[1300]\ttrain's binary_error: 0.0969444\tvalid's binary_error: 0.10738\n[1400]\ttrain's binary_error: 0.09616\tvalid's binary_error: 0.10754\n[1500]\ttrain's binary_error: 0.0952111\tvalid's binary_error: 0.10742\n[1600]\ttrain's binary_error: 0.09418\tvalid's binary_error: 0.10718\nEarly stopping, best iteration is:\n[1210]\ttrain's binary_error: 0.0978133\tvalid's binary_error: 0.10706\n\nFold_6 Training ================================\n\nTraining until validation scores don't improve for 400 rounds\n[100]\ttrain's binary_error: 0.113373\tvalid's binary_error: 0.11252\n[200]\ttrain's binary_error: 0.110029\tvalid's binary_error: 0.11056\n[300]\ttrain's binary_error: 0.108198\tvalid's binary_error: 0.11024\n[400]\ttrain's binary_error: 0.106696\tvalid's binary_error: 0.1096\n[500]\ttrain's binary_error: 0.105471\tvalid's binary_error: 0.10954\n[600]\ttrain's binary_error: 0.104269\tvalid's binary_error: 0.10938\n[700]\ttrain's binary_error: 0.103151\tvalid's binary_error: 0.10896\n[800]\ttrain's binary_error: 0.101916\tvalid's binary_error: 0.10854\n[900]\ttrain's binary_error: 0.100833\tvalid's binary_error: 0.10852\n[1000]\ttrain's binary_error: 0.0999778\tvalid's binary_error: 0.10784\n[1100]\ttrain's binary_error: 0.0992111\tvalid's binary_error: 0.10772\n[1200]\ttrain's binary_error: 0.0981867\tvalid's binary_error: 0.10772\n[1300]\ttrain's binary_error: 0.0973467\tvalid's binary_error: 0.1074\n[1400]\ttrain's binary_error: 0.0964178\tvalid's binary_error: 0.10774\n[1500]\ttrain's binary_error: 0.0954044\tvalid's binary_error: 0.1076\n[1600]\ttrain's binary_error: 0.0944956\tvalid's binary_error: 0.10756\n[1700]\ttrain's binary_error: 0.0938356\tvalid's binary_error: 0.10736\nEarly stopping, best iteration is:\n[1309]\ttrain's binary_error: 0.0972222\tvalid's binary_error: 0.10734\n\nFold_8 Training ================================\n\nTraining until validation scores don't improve for 400 rounds\n[100]\ttrain's binary_error: 0.113149\tvalid's binary_error: 0.11376\n[200]\ttrain's binary_error: 0.109544\tvalid's binary_error: 0.11242\n[300]\ttrain's binary_error: 0.107976\tvalid's binary_error: 0.11158\n[400]\ttrain's binary_error: 0.106682\tvalid's binary_error: 0.11136\n[500]\ttrain's binary_error: 0.105353\tvalid's binary_error: 0.111\n[600]\ttrain's binary_error: 0.104024\tvalid's binary_error: 0.11084\n[700]\ttrain's binary_error: 0.10284\tvalid's binary_error: 0.1101\n[800]\ttrain's binary_error: 0.101762\tvalid's binary_error: 0.11002\n[900]\ttrain's binary_error: 0.100796\tvalid's binary_error: 0.10988\n[1000]\ttrain's binary_error: 0.0997489\tvalid's binary_error: 0.10944\n[1100]\ttrain's binary_error: 0.09874\tvalid's binary_error: 0.1095\n[1200]\ttrain's binary_error: 0.0976356\tvalid's binary_error: 0.10942\n[1300]\ttrain's binary_error: 0.09672\tvalid's binary_error: 0.10942\n[1400]\ttrain's binary_error: 0.0956867\tvalid's binary_error: 0.10894\n[1500]\ttrain's binary_error: 0.0948156\tvalid's binary_error: 0.10888\n[1600]\ttrain's binary_error: 0.0936244\tvalid's binary_error: 0.10886\n[1700]\ttrain's binary_error: 0.0927533\tvalid's binary_error: 0.10896\n[1800]\ttrain's binary_error: 0.09194\tvalid's binary_error: 0.10888\nEarly stopping, best iteration is:\n[1465]\ttrain's binary_error: 0.0950533\tvalid's binary_error: 0.10872\n\nFold_9 Training ================================\n\nTraining until validation scores don't improve for 400 rounds\n[100]\ttrain's binary_error: 0.1135\tvalid's binary_error: 0.11478\n[200]\ttrain's binary_error: 0.109644\tvalid's binary_error: 0.11226\n[300]\ttrain's binary_error: 0.10798\tvalid's binary_error: 0.1114\n[400]\ttrain's binary_error: 0.106389\tvalid's binary_error: 0.111\n[500]\ttrain's binary_error: 0.105116\tvalid's binary_error: 0.11052\n[600]\ttrain's binary_error: 0.103676\tvalid's binary_error: 0.10978\n[700]\ttrain's binary_error: 0.102549\tvalid's binary_error: 0.10956\n[800]\ttrain's binary_error: 0.101696\tvalid's binary_error: 0.10926\n[900]\ttrain's binary_error: 0.100733\tvalid's binary_error: 0.1091\n[1000]\ttrain's binary_error: 0.0998022\tvalid's binary_error: 0.10904\n[1100]\ttrain's binary_error: 0.0989311\tvalid's binary_error: 0.10878\n[1200]\ttrain's binary_error: 0.0979489\tvalid's binary_error: 0.1086\n[1300]\ttrain's binary_error: 0.0970311\tvalid's binary_error: 0.10844\n[1400]\ttrain's binary_error: 0.0959889\tvalid's binary_error: 0.10832\n[1500]\ttrain's binary_error: 0.0950822\tvalid's binary_error: 0.10834\n[1600]\ttrain's binary_error: 0.0941778\tvalid's binary_error: 0.10838\n[1700]\ttrain's binary_error: 0.0932844\tvalid's binary_error: 0.108\n[1800]\ttrain's binary_error: 0.0923311\tvalid's binary_error: 0.10802\n[1900]\ttrain's binary_error: 0.0913644\tvalid's binary_error: 0.10788\n[2000]\ttrain's binary_error: 0.0905689\tvalid's binary_error: 0.10818\n[2100]\ttrain's binary_error: 0.0896956\tvalid's binary_error: 0.10822\n[2200]\ttrain's binary_error: 0.0887467\tvalid's binary_error: 0.10844\nEarly stopping, best iteration is:\n[1850]\ttrain's binary_error: 0.09176\tvalid's binary_error: 0.10788\n\nFold_10 Training ================================\n\nTraining until validation scores don't improve for 400 rounds\n[100]\ttrain's binary_error: 0.112924\tvalid's binary_error: 0.11518\n[200]\ttrain's binary_error: 0.109813\tvalid's binary_error: 0.11414\n[300]\ttrain's binary_error: 0.108047\tvalid's binary_error: 0.11338\n[400]\ttrain's binary_error: 0.10644\tvalid's binary_error: 0.11294\n[500]\ttrain's binary_error: 0.105076\tvalid's binary_error: 0.1125\n[600]\ttrain's binary_error: 0.103753\tvalid's binary_error: 0.11226\n[700]\ttrain's binary_error: 0.102622\tvalid's binary_error: 0.112\n[800]\ttrain's binary_error: 0.101653\tvalid's binary_error: 0.11192\n[900]\ttrain's binary_error: 0.100753\tvalid's binary_error: 0.11168\n[1000]\ttrain's binary_error: 0.0997244\tvalid's binary_error: 0.11148\n[1100]\ttrain's binary_error: 0.0988556\tvalid's binary_error: 0.11144\n[1200]\ttrain's binary_error: 0.0978711\tvalid's binary_error: 0.11158\n[1300]\ttrain's binary_error: 0.0969444\tvalid's binary_error: 0.11158\n[1400]\ttrain's binary_error: 0.09616\tvalid's binary_error: 0.11146\n[1500]\ttrain's binary_error: 0.0951867\tvalid's binary_error: 0.11148\n[1600]\ttrain's binary_error: 0.0942511\tvalid's binary_error: 0.11132\n[1700]\ttrain's binary_error: 0.09338\tvalid's binary_error: 0.1109\n[1800]\ttrain's binary_error: 0.0925978\tvalid's binary_error: 0.11092\n[1900]\ttrain's binary_error: 0.0915289\tvalid's binary_error: 0.11136\n[2000]\ttrain's binary_error: 0.0905667\tvalid's binary_error: 0.11116\n[2100]\ttrain's binary_error: 0.0897622\tvalid's binary_error: 0.11122\nEarly stopping, best iteration is:\n[1727]\ttrain's binary_error: 0.0931822\tvalid's binary_error: 0.11082\n"
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "               feature_fraction=0.4, importance_type='split',\n",
    "               learning_rate=0.025, max_depth=7, metric=None,\n",
    "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
    "               n_estimators=10000, n_jobs=-1, num_leaves=128, objective=None,\n",
    "               random_state=220, reg_alpha=0.3, reg_lambda=0.3, save_binary=True,\n",
    "               silent=True, subsample=0.8, subsample_for_bin=200000,\n",
    "               subsample_freq=0)\n",
    "\n",
    "oof = []\n",
    "df_importance_list = []\n",
    "n=10\n",
    "# kfold = GroupKFold(n_splits=n)\n",
    "kfold = KFold(n_splits=n,shuffle=True,random_state=220)\n",
    "for fold_id, (trn_idx, val_idx) in enumerate(kfold.split(feature_train[x_col], feature_train[y_col])):\n",
    "    # if fold_id==6:\n",
    "    #     continue\n",
    "    X_train = feature_train.iloc[trn_idx][x_col]\n",
    "    Y_train = feature_train.iloc[trn_idx][y_col]\n",
    "\n",
    "    X_val = feature_train.iloc[val_idx][x_col]\n",
    "    Y_val = feature_train.iloc[val_idx][y_col]\n",
    "\n",
    "    print('\\nFold_{} Training ================================\\n'.format(fold_id+1))\n",
    "\n",
    "    lgb_model = model.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        categorical_feature=cate_feature,\n",
    "        eval_names=['train', 'valid'],\n",
    "        eval_set=[(X_train, Y_train), (X_val, Y_val)],\n",
    "        verbose=100,\n",
    "        eval_metric=[\"binary_error\"],\n",
    "        early_stopping_rounds=400\n",
    "    )\n",
    "\n",
    "    pred_val = lgb_model.predict_proba(X_val, num_iteration=lgb_model.best_iteration_)[:, 1]\n",
    "    df_oof = feature_train.iloc[val_idx].copy()\n",
    "    df_oof['pred'] = pred_val\n",
    "    oof.append(df_oof)\n",
    "\n",
    "    pred_test = lgb_model.predict_proba(feature_test[x_col], num_iteration=lgb_model.best_iteration_)[:, 1]\n",
    "    prediction['label'] += pred_test / n\n",
    "    pred_train= lgb_model.predict_proba(X_val, num_iteration=lgb_model.best_iteration_)[:, 1]\n",
    "    prediction_train.iloc[val_idx,-2] += pred_train\n",
    "\n",
    "    df_importance = pd.DataFrame({\n",
    "        'column': x_col,\n",
    "        'importance': lgb_model.feature_importances_,\n",
    "    })\n",
    "    df_importance_list.append(df_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        column    importance\n0    timestamp  13458.666667\n1       minute  11967.000000\n2     location  10350.666667\n3     cus_type   9786.555556\n4     hw_ratio   9592.111111\n5         inch   9014.777778\n6         hour   8970.222222\n7    hw_matrix   7974.555556\n8   dev_height   7667.777778\n9    fea1_hash   6796.222222\n10    media_id   5375.888889\n11         osv   4418.333333\n12         day   4115.888889\n13     package   3521.444444\n14   dev_width   3339.000000\n15   final_ppi   2866.888889\n16     apptype   2561.888889\n17  160_height   1343.666667\n18         vpn   1305.555556\n19          os   1200.888889\n20     version   1078.000000\n21     160_ppi    823.111111\n22    fea_hash    760.222222\n23     carrier    528.666667\n24         ntt    468.666667\n25   160_width    457.666667\n26         lan    401.888889",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>column</th>\n      <th>importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>timestamp</td>\n      <td>13458.666667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>minute</td>\n      <td>11967.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>location</td>\n      <td>10350.666667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cus_type</td>\n      <td>9786.555556</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hw_ratio</td>\n      <td>9592.111111</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>inch</td>\n      <td>9014.777778</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>hour</td>\n      <td>8970.222222</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>hw_matrix</td>\n      <td>7974.555556</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>dev_height</td>\n      <td>7667.777778</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>fea1_hash</td>\n      <td>6796.222222</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>media_id</td>\n      <td>5375.888889</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>osv</td>\n      <td>4418.333333</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>day</td>\n      <td>4115.888889</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>package</td>\n      <td>3521.444444</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>dev_width</td>\n      <td>3339.000000</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>final_ppi</td>\n      <td>2866.888889</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>apptype</td>\n      <td>2561.888889</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>160_height</td>\n      <td>1343.666667</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>vpn</td>\n      <td>1305.555556</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>os</td>\n      <td>1200.888889</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>version</td>\n      <td>1078.000000</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>160_ppi</td>\n      <td>823.111111</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>fea_hash</td>\n      <td>760.222222</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>carrier</td>\n      <td>528.666667</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>ntt</td>\n      <td>468.666667</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>160_width</td>\n      <td>457.666667</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>lan</td>\n      <td>401.888889</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df_importance = pd.concat(df_importance_list)\n",
    "df_importance = df_importance.groupby(['column'])['importance'].agg('mean').sort_values(ascending=False).reset_index()\n",
    "df_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 后接lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction['label'] = prediction['label']*10/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The prediction score on the test data is 89.47%\nThe prediction score on the test data is 89.00%\n"
    }
   ],
   "source": [
    "X=prediction_train[['apptype', 'carrier', 'dev_height','hour', 'minute',\"timestamp\",\"day\",'dev_width', 'lan', 'media_id', 'ntt', 'os', 'osv', 'package', 'version', 'fea_hash', 'location', 'fea1_hash', 'cus_type', '160_height', '160_width','160_ppi', 'hw_ratio', 'inch','final_ppi','vpn', 'hw_matrix',\"label\"]].fillna(0)\n",
    "y= prediction_train[[\"label_prior\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.8, random_state=6)\n",
    "# lr = SVC(max_iter=400,C=2,kernel='rbf',tol=0.001)\n",
    "lr =LogisticRegression(C=1,)\n",
    "lr = RandomForestClassifier(n_estimators=100,max_depth=25, random_state=10,n_jobs=-1,oob_score=True,min_samples_split=100,min_samples_leaf=20,max_features='sqrt')\n",
    "# Fit on the train data\n",
    "lr.fit(X_train, y_train)\n",
    "# print (lr.oob_score_ )\n",
    "score = lr.score(X_train, y_train)\n",
    "print(\"The prediction score on the test data is {:.2f}%\".format(score*100))\n",
    "score = lr.score(X_test, y_test)\n",
    "print(\"The prediction score on the test data is {:.2f}%\".format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'mean_fit_time': array([1.87839212, 2.97730794, 4.10277395, 5.45916104, 7.11462851,\n       8.21347399, 9.3156014 ]), 'std_fit_time': array([0.33236586, 0.09477538, 0.11157893, 0.08885174, 0.42922799,\n       0.30449998, 0.13194417]), 'mean_score_time': array([0.15724292, 0.15833359, 0.20262074, 0.18448076, 0.18338523,\n       0.30296011, 0.3106585 ]), 'std_score_time': array([0.01399997, 0.01106413, 0.02680967, 0.03408281, 0.05325976,\n       0.03583993, 0.03366581]), 'param_n_estimators': masked_array(data=[10, 20, 30, 40, 50, 60, 70],\n             mask=[False, False, False, False, False, False, False],\n       fill_value='?',\n            dtype=object), 'params': [{'n_estimators': 10}, {'n_estimators': 20}, {'n_estimators': 30}, {'n_estimators': 40}, {'n_estimators': 50}, {'n_estimators': 60}, {'n_estimators': 70}], 'split0_test_score': array([0.93745058, 0.93841455, 0.9383683 , 0.93887455, 0.93846612,\n       0.93837591, 0.93829484]), 'split1_test_score': array([0.93538718, 0.93649658, 0.93636988, 0.93597485, 0.93577305,\n       0.93576121, 0.93581993]), 'split2_test_score': array([0.93808122, 0.9377301 , 0.93774109, 0.93804397, 0.93805461,\n       0.93762567, 0.93776883]), 'split3_test_score': array([0.9362768 , 0.93765073, 0.93725229, 0.93747489, 0.93751427,\n       0.93732897, 0.93765873]), 'split4_test_score': array([0.93494091, 0.93656621, 0.93632958, 0.93687582, 0.93691764,\n       0.93681291, 0.93701909]), 'mean_test_score': array([0.93642734, 0.93737164, 0.93721223, 0.93744882, 0.93734514,\n       0.93718093, 0.93731228]), 'std_test_score': array([0.00119134, 0.000736  , 0.00078821, 0.00098879, 0.00094263,\n       0.00087163, 0.00084935]), 'rank_test_score': array([7, 2, 5, 1, 3, 6, 4])}\n{'n_estimators': 40} 0.9374488163254714\n"
    }
   ],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# X=prediction_train[['apptype', 'carrier', 'dev_height','hour', 'minute',\"timestamp\",\"day\",'dev_width', 'lan', 'media_id', 'ntt', 'os', 'osv', 'package', 'version', 'fea_hash', 'location', 'fea1_hash', 'cus_type', '160_height', '160_width','160_ppi', 'hw_ratio', 'inch','final_ppi','vpn', 'hw_matrix',\"label\"]].fillna(0)\n",
    "# y= prediction_train[[\"label_prior\"]]\n",
    "\n",
    "# param_test1={'n_estimators': list(range(10,71,10))}\n",
    "# gsearch1=GridSearchCV(\n",
    "# estimator=RandomForestClassifier(min_samples_split=100,min_samples_leaf=20,max_depth=8,max_features='sqrt',random_state=10,n_jobs=-1),param_grid=param_test1,\n",
    "# scoring='roc_auc',cv=5)\n",
    "# gsearch1.fit(X,y)\n",
    "# print(gsearch1.cv_results_,gsearch1.best_params_,gsearch1.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_test2={\"max_depth\":range(10,31,3),\"min_simples_split\":range(50,201,20)}\n",
    "# gsearch2=GridSearchCV(estimator=RandomForestClassifier(n_estimator=40,min_samples_leaf=20,max_features='sqrt',random_state=10,n_jobs=-1)),\n",
    "# param_grid=param_test2,scoring=\"roc_auc\",iid=False,cv=5)\n",
    "# gsearch2.fit(X,y)  \n",
    "# print(gsearch1.cv_results_,gsearch1.best_params_,gsearch1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.to_csv('submission_0611_0221.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 直接阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(prediction.index)\n",
    "a['label'] =lgb_model.predict(feature_test[x_col], num_iteration=lgb_model.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold=0.5\n",
    "# a[\"label\"]=a.label.apply(lambda x:1 if x>threshold else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 后验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_label=pd.DataFrame()\n",
    "# user_label[\"uid\"]=feature_train.groupby(\"android_id\").count().index\n",
    "# user_label=user_label.set_index(\"uid\")\n",
    "user_label[\"uid\"]=feature_train.android_id.values\n",
    "user_label[\"ntt\"]=feature_train.ntt.values\n",
    "temp=pd.DataFrame(feature_train.groupby([\"android_id\",\"ntt\"]).label.mean())\n",
    "temp=temp.reset_index()\n",
    "temp.rename(columns={\"android_id\":\"uid\",\"label\":\"label_prior\"},inplace=True)\n",
    "# user_label[\"label_prior\"]=feature_train.groupby([\"android_id\",\"ntt\"]).label.transform(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_label=pd.merge(user_label,temp,on=[\"uid\",\"ntt\"],how=\"left\")\n",
    "user_label.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"uid\"]=feature_test.android_id.values\n",
    "a[\"ntt\"]=feature_test.ntt.values\n",
    "a=pd.merge(a,user_label,how=\"left\",on=[\"uid\",\"ntt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post(label,prior):\n",
    "    n=len(label)\n",
    "    count=0\n",
    "    for i in range(n):\n",
    "        if 0<=prior[i]<=0.1 and label[i]==1:\n",
    "            label[i]=0\n",
    "            count+=1\n",
    "            # print(i)\n",
    "        elif 0.9<=prior[i]<=1 and label[i]==0:\n",
    "            label[i]=1\n",
    "            count+=1\n",
    "            # print(i)\n",
    "        else:\n",
    "            pass\n",
    "    print(count)\n",
    "    return label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "367\n"
    }
   ],
   "source": [
    "a.label=post(a.label,a.label_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=a[[\"sid\",\"label\"]]\n",
    "a.to_csv('submission_0617_2144.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            sid  label\n0       1440682      0\n1       1606824      1\n2       1774642      0\n3       1742535      0\n4       1689686      1\n...         ...    ...\n149995  1165373      1\n149996  1444115      1\n149997  1134378      1\n149998  1700238      1\n149999  1201539      1\n\n[150000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sid</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1440682</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1606824</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1774642</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1742535</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1689686</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>149995</th>\n      <td>1165373</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>149996</th>\n      <td>1444115</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>149997</th>\n      <td>1134378</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>149998</th>\n      <td>1700238</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>149999</th>\n      <td>1201539</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>150000 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n               feature_fraction=0.4, importance_type='split',\n               learning_rate=0.025, max_depth=7, metric=None,\n               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n               n_estimators=10000, n_jobs=-1, num_leaves=128, objective=None,\n               random_state=220, reg_alpha=3, reg_lambda=3, save_binary=True,\n               silent=True, subsample=0.8, subsample_for_bin=200000,\n               subsample_freq=0)"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}